name: Tests and Linting

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  lint-and-type-check:
    name: Lint and Type Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e '.[dev]'

      - name: Run ruff
        run: ruff check lotus/

      - name: Run mypy
        run: mypy lotus/

  tests:
    name: Run Tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        test-suite: [lm-openai, lm-ollama, rm, multimodality, utility_operators, cache]
        include:
          - test-suite: lm-openai
            file: .github/tests/lm_tests.py
            timeout: 10
            requires-openai: true
          - test-suite: lm-ollama
            file: .github/tests/lm_tests.py
            timeout: 20
            requires-ollama: true
          - test-suite: rm
            file: .github/tests/rm_tests.py
            timeout: 10
            requires-openai: true
          - test-suite: multimodality
            file: .github/tests/multimodality_tests.py
            timeout: 10
            requires-openai: true
          - test-suite: utility_operators
            file: .github/tests/utility_operators_tests.py
            timeout: 10
            extra-deps: pymupdf llama-index docx2txt python-pptx python-magic
          - test-suite: cache
            file: .github/tests/cache_tests.py
            timeout: 10
            requires-ollama: true

    timeout-minutes: ${{ matrix.timeout }}

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - uses: actions/cache@v3
        with:
          path: ~/.cache/uv
          key: ${{ runner.os }}-uv-${{ hashFiles('uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-uv-

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e '.[dev]'
          if [ "${{ matrix.extra-deps }}" != "" ]; then
            uv pip install --system ${{ matrix.extra-deps }}
          fi

      - name: Setup Ollama
        if: ${{ matrix.requires-ollama }}
        run: |
          docker pull ollama/ollama:latest
          docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
          timeout=120
          while ! curl -s http://localhost:11434/ >/dev/null; do
            if [ $timeout -le 0 ]; then
              echo "Timed out waiting for Ollama server"
              exit 1
            fi
            echo "Waiting for Ollama server to be ready..."
            sleep 1
            timeout=$((timeout - 1))
          done
          if [ "${{ matrix.test-suite }}" = "lm-ollama" ]; then
            docker exec $(docker ps -q) ollama run llama3.1
          elif [ "${{ matrix.test-suite }}" = "cache" ]; then
            docker exec $(docker ps -q) ollama run llama3.2:3b
          fi

      - name: Run tests
        env:
          ENABLE_OLLAMA_TESTS: ${{ matrix.requires-ollama }}
          ENABLE_OPENAI_TESTS: ${{ matrix.requires-openai }}
          ENABLE_LOCAL_TESTS: ${{ matrix.test-suite == 'rm' }}
        run: pytest ${{ matrix.file }}